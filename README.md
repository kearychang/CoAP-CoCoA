# CPS716
CoAP and Proxy

CoAP implementation (may not be compatible with NS-3)
http://programmingwithreason.com/article-iot-coap.html
NS-3 PDF
https://www.nsnam.org/docs/release/3.28/tutorial/ns-3-tutorial.pdf
JAVA Californium
https://github.com/eclipse/californium

GPRS and IEEE 802.15.4 are used in this article for evaluations in two respective experimental
setups, which also use different hardware to run CoAP servers and clients.

GPRS is a common M2M technology that allows a fl exible network setup for Internet connectivity.
IEEE 802.15.4 targets low-power communication and is a common interface employed
by many IoT standards, including ZigBee and 6LoWPAN. 
GPRS and IEEE 802.15.4 are interesting for this study because they have different
bit rates and delay characteristics. Moreover, GPRS involves a single wireless hop, whereas
IEEE 802.15.4 networks are often deployed as multihop networks.

In the first setup, a laptop running CoAP clients uses a Matrix MTX-65-ULP GPRS modem
to connect to the Internet, from where packets are routed toward a PC running a CoAP server.
When compared to a wired connection, much larger RTTs and much higher RTT jitter are
observed over the GPRS link, as well as a higher chance of packet losses. In our testbed we
observe uplink/downlink data rates of approximately 15/40 kb/s.

In this setup, both the CoAP clients and server run the Java Californium (Cf) CoAP [6]
implementation. The alternative congestion control mechanisms considered in this article are
implemented and publicly available in Cf.5 For a fair comparative evaluation, while the PH-RTO
and Linux algorithms were designed for TCP, we have implemented these algorithms for CoAP (over UDP). 
Other TCP features are not present in our evaluation.

In the second setup, the interaction between a cloud service and a multihop low-power wireless
network is analyzed. CoAP clients running in the cloud service are connected via Ethernet
to an IEEE 802.15.4 testbed where all motes run CoAP servers. 
FlockLab, a publicly available IEEE 802.15.4 indoor/outdoor testbed composed of 30 TelosB motes [7], is chosen for this setup. 
The FlockLab motes run ContikiMAC [8] with radio duty cycling (RDC) enabled, which is required to save energy in real deployments. 
On the client side, Cf is used as the CoAP implementation, while the server motes in FlockLab run the full IPv6-based
ContikiOS stack for constrained devices, including the Erbium (Er) CoAP implementation [9].

TRAFFIC SCENARIOS
For both testbeds (GPRS and FlockLab), two traffic scenarios are defined to explore the effect
of different congestion control mechanisms on the performance of CoAP communications.

Continuous Traffic: In this scenario, CoAP clients send CON requests to a CoAP server. 
When a client receives a reply from the server, the client immediately sends another CON request. 
Sending messages back-to-back by many clients simultaneously can create congestion. 
The number of clients is varied from 10 to 40 (in steps of 10) in order to achieve different degrees of congestion.

In the GPRS setup, one server is running on the destination device. 
In FlockLab, one client is assigned to each CoAP server mote in the testbed.
A continuous traffic test lasts 180 s.

Burst Traffic: This scenario starts with a low congestion level, where 10 clients (GPRS) or 5 clients (FlockLab) generate continuous traffic of back-to-back CON requests. Then a burst of traffic is generated by a new group of clients that send 50 (GPRS) or 25 (FlockLab) back-toback CON requests to the servers. Such traffic patterns can correspond to a local event (alerts about presence, temperature, etc.). The burst of messages causes a congestion peak. For the GPRS setup, we vary the number of clients that
generate burst traffic. In FlockLab, for each mote that is not a destination of continuous traffic, we create a client that generates burst traffic.
